{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJMhzBJh/grB7arwWaotqA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/audreynrr/ProjetDATA2526/blob/main/Cours_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2zWGLbyqjHL6",
        "outputId": "a773bc98-2d31-44ba-efee-7ff2f2642cf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting numby\n",
            "  Downloading numby-0.2.0-py3-none-any.whl.metadata (380 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading numby-0.2.0-py3-none-any.whl (1.1 kB)\n",
            "Installing collected packages: numby\n",
            "Successfully installed numby-0.2.0\n"
          ]
        }
      ],
      "source": [
        "# Quel package utilisé pour le biais vs la variance ?\n",
        "# Usuellement on a\n",
        "# scikitlearn\n",
        "!pip install scikit-learn matplotlib numby pandas seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloc des Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "nB3t1PG8kJV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sachez que certains packages ont des datasets de saivegardés !\n",
        "# Sci kit learn propose celui des housing californiens.\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "7ebAu2qnkzqH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ef407b8"
      },
      "source": [
        "## Common Functions/Tasks in Machine Learning\n",
        "\n",
        "Machine Learning algorithms are typically categorized based on the type of problem they solve. Here are some of the most common 'functions':\n",
        "\n",
        "1.  **Regression**: Predicting a continuous numerical value (e.g., house prices, temperature, stock prices).\n",
        "2.  **Classification**: Predicting a categorical label (e.g., spam/not spam, disease/no disease, type of animal).\n",
        "3.  **Clustering**: Grouping similar data points together without prior knowledge of groups (e.g., customer segmentation).\n",
        "4.  **Dimensionality Reduction**: Reducing the number of features or variables while retaining important information (e.g., for visualization or to speed up algorithms).\n",
        "\n",
        "Let's demonstrate **Regression** using the California Housing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "105e4ce1"
      },
      "source": [
        "# Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data  # Features\n",
        "y = housing.target # Target (median house value)\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(\"Features names:\", housing.feature_names)\n",
        "print(\"Target name:\", housing.target_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a082046"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"R-squared: {r2:.2f}\")\n",
        "\n",
        "# Display some actual vs predicted values\n",
        "import pandas as pd\n",
        "comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "display(comparison_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98252ce3"
      },
      "source": [
        "This example demonstrates a regression task where we train a model to predict continuous house values based on various features. The Mean Squared Error and R-squared metrics tell us how well our model performed.\n",
        "\n",
        "### Classification Example\n",
        "\n",
        "For **Classification**, we would use a dataset where the target variable is categorical (e.g., predicting if a person has heart disease based on medical features). A common algorithm for classification is `LogisticRegression` or `SVC` (Support Vector Classifier).\n",
        "\n",
        "```python\n",
        "# Example of Classification (conceptual code)\n",
        "# from sklearn.datasets import load_iris\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# iris = load_iris()\n",
        "# X_cls, y_cls = iris.data, iris.target\n",
        "\n",
        "# X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(X_cls, y_cls, test_size=0.2, random_state=42)\n",
        "\n",
        "# classifier = LogisticRegression(max_iter=200) # Increase max_iter for convergence\n",
        "# classifier.fit(X_train_cls, y_train_cls)\n",
        "# y_pred_cls = classifier.predict(X_test_cls)\n",
        "# accuracy = accuracy_score(y_test_cls, y_pred_cls)\n",
        "# print(f\"Classification Accuracy: {accuracy:.2f}\")\n",
        "```\n",
        "\n",
        "There are many more algorithms and techniques within each of these functions, but this covers the primary types of problems Machine Learning aims to solve."
      ]
    }
  ]
}